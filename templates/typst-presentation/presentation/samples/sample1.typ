#import "@preview/touying:0.5.3": *
#import "@preview/curryst:0.3.0" as curryst: rule

#import "theme.typ": *

#show: university-theme.with(
  config-colors(
    primary: primary-color,
    secondary: secondary-color,
    tertiary: tertiary-color,
    neutral-darkest: text-color
  ),
  config-info(
    title: [Modern Type Theory],
    subtitle: [An introduction to modern dependent type theory],
    author: [Ridan Vandenbergh],
    date: datetime.today(),
    institution: [KU Leuven],
  ),
)

#set heading(numbering: "1.")

#title-slide()

= Introduction

== Overview

Why study types?

- to introduce *rigorous correctness* to programming languages
- to understand the core theory in *proof assistants* like Agda, Coq, ...
- to formalize a *new set of foundations* for mathematics #footnote([As an alternative to ZFC set theory])
- to draw commutative diagrams you can be proud of

#large-center-text(emoji.construction)

What we'll discuss in this course:

- The design of a good type theory
- Logic as an *emergent property*
- Martin-LÃ¶f (extensional) type theory
- Concepts from category theory presented in type theory

#large-center-text(emoji.construction)

== Set theory vs type theory

As we present type theory as a suitable replacement for set theory as a foundation of mathematics, it's worth nothing the differences:

#table(
  columns: (1fr,1fr),
  stroke: none,
  fill: (_, y) => if calc.even(y) { white.darken(10%) },
  inset: 8pt,
  table.header[#text(weight: "bold")[Set theory]][#text(weight: "bold")[Type theory]],
  [Comprised of two layers: #box[First-order] logic with axioms for the theory on top],[Is its own deductive system: no dependency on logic],
  [Two basic notions: sets and propositions],[One basic notion: _types_],
  [One deductive outcome#footnote[We'll start calling these _judgements_ soon]: $A$ has a proof.],[Several deductive outcomes: introducing types, variables, ...]
)

= Foundations

== Deductive system

=== Judgements

One word we'll come across often is *judgement*:

#definition("judgement")[
  A judgement is the _assertion_ or _validation_ of some *proposition* $P$, hence the claim of a *proof* of $P$.
]

To distinguish a proposition from a judgement, the turnstile symbol is used:

#place(right)[#set text(black.lighten(40%));  _I know $P$ is true._]
$
âŠ¢ P
$

If our "proof" of $P$ is based on assumptions, we write those in front of the âŠ¢ :
#place(right)[#set text(black.lighten(40%));  _From $A$, I know that $P$._]
$
A âŠ¢ P
$

Judgements form a core building block of our type theory.


As seen in the introduction, type theory is its own deductive system.
Let's define that:

#definition("deductive system")[
  A deductive system (or, sometimes, *inference system*) is specified by
  + A collection of allowed *judgements*, and
  + A collection of _steps_, each of which has a (typically finite) list of judgments as hypotheses and a single judgment as conclusion.
    A step is usually written as \
    #inf-rules(inset: 0%, rule($J$, $J_1$, [...], $J_n$)) \
    If $n "is" 0$, the step is often called an *axiom*.
]

---

The steps of a deductive system are generated by *inference rules*, which are schematic ways of describing collections of steps, generally involving metavariables.

For example, consider the following inference rule, describing a simple congruence:

#inf-rules(
  rule([$S(x) = S(y)$], [$x = y$], name: smallcaps[cong])
)

Here, $x$ and $y$ are variables.
Substituting particular terms for them will yield a _step_ which is an instance of this inference rule.

---

In type theory, every element _by its very nature_ is an element of some type.
Introducing a variable, therefore, requires specifying its type.

We will be using the following judgements:

#box(inset: 10%)[
  #show math.equation: inf-style
  - $A type$    #h(1fr) $A$ is a (well-formed) type.
  - $Î“ cx$      #h(1fr) $Î“$ is a (well-formed) context.
  - $a : A$     #h(1fr) $a$ is an object of type $A$.
  - $a â‰¡ b : A$ #h(1fr) $a$ and $b$ are definitionally equal objects of type $A$.
]

Not every presentation of type theory will brandish the same set of judgements. \
In particular, the canonical version of homotopy type theory as presented by _the_ HoTT book, only includes 2 judgements (the third and fourth)!

== What's in a type?

Types may _look like_ sets, but they are not!

In type theory, a type:
- is a first-class mathematical object
- types may or may not have *inhabitants* (values of that type)
- types are not iterable, quantifiable over or have cardinality

We'll formalize how to define a set of *base types*, \
and how we *construct* types from other types, \
forming a simple process to create types by *induction*.

---

There is a general pattern for introduction of a new kind of type.
We specify:

- *formation rules* for the type: for example, we can form the \ function type $A -> B$ when $A$ is a type and when $B$ is a type.
- *constructors* for its elements: for example, a function type has one constructor, #box[$Î»$-abstraction].
- *eliminators*: How to use the type's elements, for example function application.
- a *computation rule*#footnote[also referred to as $beta$-reduction or $beta$-equivalence], which expresses how an eliminator acts on a constructor.

- an optional *uniqueness principle*#footnote[also referred to as $eta$-expansion. When the uniqueness principle is not taken as a rule of judgemental equality, it is often nevertheless provable as a _propositional_ equality.], which expresses uniqueness of maps into or out of that type.

---

#definition("type")[
  A type is a first-class mathematical object defined by a set of *formation rules*, *constructors*, *eliminators*, *computation rules* and an optional *uniqueness principle*.
]

A type#footnote[In type theory. Types in #stlc, for example, behave differently.] is nothing more and nothing less than the behaviour as described by its rules.

= Simply typed lambda calculus

== Terms in #stlc

The theory of functional programming is built on extensions of a core language known as the _simply-typed lambda calculus_ (henceforth abbreviated #stlc).

#stlc is composed of two kinds of _sorts_: *types* and *terms*.

We can define types in this calculus as expressions generated by the grammar

$ "Types" A,B := bold(b) | A times B | A -> B. $

Note the included $bold(b)$ type: without it the grammar would have no terminal symbols.

Equivalently, the #inf-style[$A type$] judgement may be derived from a number of inference rules corresponding to the production rules of $"Types"$:

#inf-rules(
  rule([$bold(b) type$]),
  rule([$A times B type$], [$A type$], [$B type$]),
  rule([$A -> B type$], [$A type$], [$B type$]),
)

See how each rule derives *a new judgement* from a number of other judgements.

---

Remember that an inference rule is a form of a generic step, with metavariables we must fill in.

By combining these rules into a tree of steps whose leaves have no premises, we can produce _derivations_ of judgements.

#[
  The tree below is a proof that
  #show "b": $bold(b)$
  #inf-style[$(b times b) -> b$] is a type:

  #let btype = rule([$b type$])
  #inf-rules(
    rule(
      [$(b times b) -> b type$],
      rule(
        [$b times b type$],
        btype, btype
      ),
      btype
    )
  )
]

It is imperative to remember and learn to identify the metavariables in inference rules, as we'll be using them very often.

---

Terms are however, considerably more difficult to define due to two issues:
- There are infinitely many sorts of terms (one for each type)
- *#set text(black); The body #underline[b] of a function $Î» x. underline(b) : A -> B$ is a term of type $B$ of our grammar _extended_ by a new constant $x: A$*!

To account for these extensions, we will introduce the concept of a *context* first.

---

=== Context

#v(-1em) // to make the last sentence fit
#definition("context")[
The judgement #inf-style[$âŠ¢ Î“ cx$] ("$Î“$ is a context") expresses that $Î“$ is a list of pairs of term variables ($x$, $y$, ...) with types ($A$, $B$, ...).
]

We write $bold(1)$ for the empty context and $Î“, x:A$ for the extension of $Î“$ by a variable $x$ with type $A$.

The #inf-style[$âŠ¢ Î“ cx$] judgement may be derived from the following inference rules:

#inf-rules(
  inset: 20%,
  rule([$âŠ¢ bold(1) cx$]),
  rule([$âŠ¢ Î“\,x:A cx$], [$âŠ¢ Î“ cx$], [$A type$], name: smallcaps[cx-ext]),
)

A context $Î“$ expresses the "parameter space" types have access to, enabling us to specify the variables that a dependent type depends on.

== Terms and computation

Now, defining terms becomes relatively straightforward, encompassing a number of rules:

#inf-rules(
  rule($Î“ âŠ¢ x : A$, $(x:A) in Î“$, $Î“ cx$),
  rule($Î“ âŠ¢ mono(c) : bold(b)$, $"a base term" mono(c)$, $Î“ cx$),
  rule($Î“ âŠ¢ (a,b): A times B$, $Î“ âŠ¢ a : A$, $Î“ âŠ¢ b : B$),
  rule($Î“ âŠ¢ fst(p) : A$, $Î“ âŠ¢ p : A times B$),
  rule($Î“ âŠ¢ snd(p) : B$, $Î“ âŠ¢ p : A times B$),
  rule($Î“ âŠ¢ Î» x.b : A -> B$, $Î“,x:A âŠ¢ b : B$),
  rule($Î“ âŠ¢ f" "a : B$, $Î“ âŠ¢ a : A$, $Î“ âŠ¢ f : A -> B$),
)

#inf-style[$Î“ âŠ¢ x:A$] is read "$x$ has type $A$ in context $Î“$."

Note that these contain the construction and elimination rules for all types in #stlc.

---

Finally, we must not forget the computation rules, which introduce a notion of sameness to our theory:

#inf-rules(
  inset: 5%,
  rule($Î“ âŠ¢ fst((a,b)) â‰¡ a : A$, $Î“ âŠ¢ a : A$, $Î“ âŠ¢ b : B$),
  rule($Î“ âŠ¢ snd((a,b)) â‰¡ b : B$, $Î“ âŠ¢ a : A$, $Î“ âŠ¢ b : B$),
  rule($Î“ âŠ¢ p â‰¡ (fst(p), snd(p)) : A times B$, $Î“ âŠ¢ p : A times B$),
  rule($Î“ âŠ¢ (Î» x.b) â‰¡ b[a\/x]:B$, $Î“,x:A âŠ¢ b:B$, $Î“ âŠ¢ a:A$),
  rule($Î“ âŠ¢ f â‰¡ Î» x.(f" "x):A->B$, $Î“ âŠ¢ f : A->B$)
)

The substitution operator $Phi[x\/y]$ means replacing every occurrence of $y$ with $x$ in $Phi$.
For a definition, refer to the book.

// TODO: this shouldn't be a subsec..
// == Exercise <touying:hidden>
//
// Attempt to derive that $Î» x. ()$ is a term.
//
// #large-center-text[#todo()]

= Towards dependent type theory

== Types and contexts

Just as we did with the judgement for terms, we will continue by extending the type judgement using contexts:

#inf-style[$A type$] becomes #inf-style[$Î“ âŠ¢ A type$] read "$A$ is a type in context $Î“$."

This has many downstream implications: we must now take into account _in what context_ a type is well-formed. A handful of rules must be updated, starting with the #inf-style[cx] judgement:

#inf-rules(
  rule([$âŠ¢ Î“\,x:A cx$], [$âŠ¢ Î“ cx$], [$Î“ âŠ¢ A type$], name: smallcaps[cx-ext']),
)

For the rest, you are invited to update those in your head.

---

Armed with term variable context added to the type judgment, we can now explain when $(x : A) -> B$ is a well-formed type:

#inf-rules(
  rule([$Î“ âŠ¢ (x : A) -> B type$], [$Î“ âŠ¢ A type$], [$Î“,x:A âŠ¢ B type$])
)

This is an example of a *formation rule*.

== Type and term dependency

We can categorize type systems into three 'tiers' of dependency:

- It may be *not dependent*, disallowing a type to be parameterized by another type. For example, C's type system is not dependent.
- It may have *uniform dependency*: types and terms may be parameterized by _other types_. Generic types in Java are an example of uniformly parameterized types.
- Or, ultimately, a type system exhibits *full-spectrum dependency* when types are indexed by terms.

---

=== Full-spectrum dependency

To achieve full-spectrum dependency, a type system must allow types to depend on other types and values, such as the following type family indexed by #inf-style[$"Nat"$]:

#align(center)[
  ```agda
  nary : Set â†’ Nat â†’ Set
  nary ğ´ 0 = ğ´
  nary ğ´ (suc ğ‘›) = ğ´ â†’ nary ğ´ ğ‘›
  ```
]

`nary` takes a type $A$, some number #inf-style[$n : "Nat"$] and produces a function of the shape:
$ underbrace(A -> ..., n "times") -> A $

Evidently, the _structure_ of the resulting type is based on the input $n$. \
This is a feat only a type system with full-spectrum dependency supports.

== Substitution calculus

#[
  #set text(0.99em)

  Let us turn our attention to what is called the *variable rule*:

  #inf-rules(
    rule([$Î“, x : A âŠ¢ x : A$], name: smallcaps[var])
  )

  Although this looks sensible, this rule's assumptions do not hold:
  - #underline[Assumption 1]: #inf-style[$âŠ¢ (Î“, x:A) cx$]
    - We could add #inf-style[$âŠ¢ Î“ cx$] and #inf-style[$Î“ âŠ¢ A type$] to the premise for this to hold, but ..
  - #underline[Assumption 2]: #inf-style[$Î“,x:A âŠ¢ A type$]
    - .. even then, #inf-style[$Î“ âŠ¢ A type$] does not imply #inf-style[$Î“, x:A âŠ¢ A type$]! \
      This would require us to prove a _weakening lemma_ for types, which is not trivial.

  Instead of that approach, or adding a silent weakening rule#footnote[#inf-style[$Î“,x:AâŠ¢B type$ when $Î“âŠ¢B type$], but this introduces ambiguity into our rules.], we will opt to introduce *explicit weakening*.
]

---

The *explicit weakening rule* asserts the existence of an operation sending types and terms in context $Î“$ to types and terms in context $Î“,x:A$, both written #inf-style[$-"[p]"$]#footnote[The p stands for projection. We'll see why later.].

#inf-rules(
  rule($Î“,x:AâŠ¢B"[p]" type$, $Î“âŠ¢B type$, $Î“âŠ¢A type$),
  rule($Î“,x:AâŠ¢b"[p]":B"[p]"$, $Î“âŠ¢b:B$, $Î“âŠ¢A type$)
)

Using these rules, we can fix the variable rule from before:

#inf-rules(
  rule($Î“,x:AâŠ¢x:A"[p]"$, $âŠ¢Î“ cx$, $Î“âŠ¢A type$, name: smallcaps[var])
)

Bringing us to a safe and unambiguous variable rule.

---

To use variables that occur earlier in the context, we can apply weakening repeatedly until they are the last variable.

#[
  #show math.equation: inf-style
  Suppose we want to use $x$ in the context $(x:A,y:B)$:
  #place(left)[We know that]
  #place(right)[#set text(black.lighten(40%));  _Apply variable rule_]
  #align(center)[$x:AâŠ¢x:A"[p]"$]

  #place(left)[And so]
  #place(right)[#set text(black.lighten(40%));  _Apply weakening_]
  #align(center)[$x:A,y:BâŠ¢x"[p]":A"[p]""[p]".$]

  In general, we can derive the following principle:

  #let princ = inf-rules(
    inset: 0%,
    rule(
      $Î“,x:A,y_1:B_1,...,y_n:B_nâŠ¢x underbrace("[p]"..."[p]", n "times") : A underbrace("[p]"..."[p]", n+1 "times")$,
      $Î“âŠ¢A type$,
      $Î“,x:AâŠ¢B_1 type$,
      $...$,
      $Î“,x:A,y_1:B_1,...âŠ¢B_n type$
    )
  )
  #princ

  ---

  #princ

  #v(.5em) // the underbraces hug the text just a bit too closely without this

  As "happy accident" of this approach we find is that the term $x"[p]"^n$ encodes in two ways which variable it refers to:
  - by the name $x$,
  - but also by the number of weakenings $n$ (called the variable's *de Bruijn index*),

  so we might as well drop variable names altogether!

  From now on, we can present contexts as lists of types $A.B.C$ with no variable names, and adopt a single notation for "the last variable in the context".#footnote[Freeing us from the torment of explaining variable binding.]

]

---

#definition("simultaneous substitution")[
  A simultaneous substitution (henceforth, just *substitution*) is an arbitrary composition of
  - zero or more *weakenings*
  - zero or more *term substitutions*
  A substitution can turn any context $Î“$ into any other context $Î”$.
]


Rather than axiomatizing _single_ term substitutions and weakenings, we will axiomatize the concept of a simultaneous substitution instead.

---

For this, we will add one final basic judgement to our theory:

#inf-rules( // abuse :)
  inset: 20%,
  $Î”âŠ¢Î³:Î“$,
  ["$Î³$ is a substitution from $Î”$ to $Î“$"]
)

corresponding to operations that send types/terms from context $Î“$ to context $Î”$#footnote[If this notation seems backward to you, you must learn to live with it.].

#underline[Notation]
#[
  #show math.equation: inf-style
  We write
  - $Cx$ for the set of contexts,
  - $Sb(Î”, Î“)$ for the set of substitutions from $Î”$ to $Î“$,
  - $Ty(Î“)$ for the set of types in context $Î“$,
  - and $Tm(Î“, A)$ for the set of terms of type $A$ in context $Î“$.
]

= Martin-LÃ¶f type theory

== <touying:hidden> // FIXME: needed to get the content not to display on the title slide

Now we _finally_ have everything we need to discuss the dependent type theory as described by Martin-LÃ¶f:

The rules for contexts are as previous, but without variable names:

#inf-rules(
  inset: 20%,
  rule($âŠ¢ bold(1) cx$),
  rule($âŠ¢Î“.A cx$, $âŠ¢Î“ cx$, $Î“âŠ¢A type$, name: smallcaps[cx-ext])
)

The purpose of a substitution $Î”âŠ¢ğ›¾:Î“$ is to shift types and terms from context $Î“$ to context $Î”$:

#inf-rules(
  rule($Î”âŠ¢A[Î³] type$, $Î”âŠ¢Î³:Î“$, $Î“âŠ¢A type$),
  rule($Î”âŠ¢Î±[Î³]:A[Î³]$, $Î”âŠ¢Î³:Î“$, $Î“âŠ¢Î±:A$)
)

---

The simplest interesting substitution is weakening, written $fat(p)$:

#inf-rules(
  rule($Î“.AâŠ¢fat(p):Î“$, $Î“âŠ¢A type$)
)

In concert with the substitution rules and $fat(p)$, we can recover the weakening rule seen previously.
Further, we have rules that close substitutions under nullary and binary composition:

#inf-rules(
  rule($Î“âŠ¢id:Î“$, $âŠ¢Î“ cx$),
  rule($Î“_2âŠ¢Î³_0 compose Î³_1 : Î“_0$, $Î“_2âŠ¢Î³_1:Î“_1$, $Î“_1âŠ¢Î³_0:Î“_0$)
)

---

And these operations are unital and associative, as one might expect:

#inf-rules(
  inset: 0%,
  rule($Î”âŠ¢Î³ compose id = id compose Î³ = Î³ : Î“$, $Î”âŠ¢Î³:Î“$),
  rule($Î“_3âŠ¢Î³_0 compose (Î³_1 compose Î³_2) = (Î³_0 compose Î³_1) compose Î³_2 : Î“_0$, $Î“_3 âŠ¢ Î³_2 : Î“_2$, $Î“_2âŠ¢Î³_1:Î“_1$, $Î“_1âŠ¢Î³_0:Î“_0$)
)#footnote[Yes, composition is reversed just like the $Î”âŠ¢Î³:Î“$ syntax.]

#todo(content: [TODO: put a[id]=a and substitution of composition is composition of substitution here?])

---

As we've done away with variable names, we update the variable rule as follows:

#inf-rules(
  rule($Î“.AâŠ¢ fat(q):A"[p]"$, $Î“âŠ¢A type$, name: smallcaps[var])
)

We will use $fat(q)$ to unambiguously refer to the last variable in the context. A variable in our system is a term of the form $fat(q)[fat(p)^n]$, where $n$ is its de Bruijn index.

#todo(content: [TODO: terminal substitutions and substitution extension])

